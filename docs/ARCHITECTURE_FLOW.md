# Architecture Flow: Complete Lambda Pipeline

## ğŸ“Š The Correct Flow (YES, This is Right!)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 1: Upload Log File                                            â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                           â”‚
â”‚  User uploads: errors_json_native.log                               â”‚
â”‚  Destination: s3://your-bucket/incidents/demo.log                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â”‚ S3 Event Trigger
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 2: Log Streamer Lambda (lambda_log_streamer.py)               â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€             â”‚
â”‚  â€¢ Reads file from S3                                               â”‚
â”‚  â€¢ Parses timestamps from JSON                                      â”‚
â”‚  â€¢ Simulates real-time by adding delays                             â”‚
â”‚  â€¢ Writes DIRECTLY to CloudWatch Logs âœ…                            â”‚
â”‚                                                                      â”‚
â”‚  Output: CloudWatch Logs (one log group per service)                â”‚
â”‚    â”œâ”€ /aws/incident-commander/auth                                  â”‚
â”‚    â”œâ”€ /aws/incident-commander/payment                               â”‚
â”‚    â”œâ”€ /aws/incident-commander/inventory                             â”‚
â”‚    â””â”€ /aws/incident-commander/checkout                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â”‚ CloudWatch Logs Subscription Filter
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 3: Log Segregator Lambda (lambda_log_segregator.py)           â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€             â”‚
â”‚  â€¢ Triggered by CloudWatch Logs (real-time!)                        â”‚
â”‚  â€¢ Reads latency_ms from each error log                             â”‚
â”‚  â€¢ Categories errors:                                                â”‚
â”‚    - Fast failures (<100ms)                                          â”‚
â”‚    - Medium latency (100-500ms)                                      â”‚
â”‚    - Slow failures (500-2000ms)                                      â”‚
â”‚    - Critical timeouts (>2000ms)                                     â”‚
â”‚  â€¢ Writes to S3 in organized folders                                 â”‚
â”‚                                                                      â”‚
â”‚  Output: s3://categorized-bucket/categorized/{category}/            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 4: Incident Detection                                         â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                            â”‚
â”‚  CloudWatch Metric Alarm detects high error rate                    â”‚
â”‚  Triggers: EventBridge â†’ Step Functions                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 5: Agent Analysis (agent_logs_analyzer.py)                    â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                   â”‚
â”‚  Step Functions invokes this Lambda                                 â”‚
â”‚                                                                      â”‚
â”‚  Agent makes API calls to:                                          â”‚
â”‚  âœ… CloudWatch Logs Insights API (query logs)                       â”‚
â”‚  âœ… S3 API (read categorized logs)                                  â”‚
â”‚                                                                      â”‚
â”‚  Returns findings to Step Functions                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## âœ… Your Understanding is CORRECT!

**Q: "Can Lambda send directly to CloudWatch?"**
**A:** YES! âœ… Use `logs_client.put_log_events()` API

**Q: "Agent code will read from CloudWatch?"**
**A:** YES! âœ… Use CloudWatch Logs Insights API: `logs_client.start_query()`

**Q: "API calls happen in agent code?"**
**A:** YES! âœ… Agent Lambda calls:
- CloudWatch Logs Insights API (to query logs)
- S3 API (to read categorized logs)
- Returns analysis to Step Functions

---

## ğŸš€ How to Use These Files

### 1. Set Your S3 Bucket Name

Replace in Terraform or as environment variable:
```bash
export SOURCE_BUCKET="your-incident-logs-bucket"
export CATEGORIZED_BUCKET="your-categorized-logs-bucket"
```

### 2. Deploy Lambda Functions

```bash
# Package log streamer
cd /path/to/lambda_log_streamer
pip install -r requirements_lambda.txt -t .
zip -r lambda_log_streamer.zip .

# Package log segregator
cd /path/to/lambda_log_segregator
zip lambda_log_segregator.zip lambda_log_segregator.py

# Package agent
cd /path/to/agent_logs_analyzer
zip agent_logs_analyzer.zip agent_logs_analyzer.py

# Upload to AWS Lambda (via Terraform or AWS CLI)
```

### 3. Configure CloudWatch Log Groups

Create log groups (Terraform will do this):
```bash
aws logs create-log-group --log-group-name /aws/incident-commander/auth
aws logs create-log-group --log-group-name /aws/incident-commander/payment
aws logs create-log-group --log-group-name /aws/incident-commander/inventory
aws logs create-log-group --log-group-name /aws/incident-commander/checkout
aws logs create-log-group --log-group-name /aws/incident-commander/recommendation
```

### 4. Set Up CloudWatch Subscription Filter

Terraform will create this, or manually:
```bash
aws logs put-subscription-filter \
  --log-group-name "/aws/incident-commander/payment" \
  --filter-name "latency-segregation" \
  --filter-pattern '{ $.level = "ERROR" }' \
  --destination-arn "arn:aws:lambda:REGION:ACCOUNT:function:incident-log-segregator"
```

### 5. Upload Your Log File

```bash
aws s3 cp errors_json_native.log \
  s3://YOUR-BUCKET/incidents/demo-incident.log
```

This triggers the entire pipeline! ğŸ‰

---

## ğŸ“ Lambda Environment Variables

Set these in Terraform or AWS Console:

**lambda_log_streamer.py:**
- `SPEED_MULTIPLIER=10.0` (stream 10x faster)
- `LOG_GROUP_PREFIX=/aws/incident-commander`

**lambda_log_segregator.py:**
- `CATEGORIZED_LOGS_BUCKET=your-bucket-name`

**agent_logs_analyzer.py:**
- (Gets parameters from Step Functions event)

---

## ğŸ” Testing Locally

```python
# Test log streamer
python lambda_log_streamer.py

# Simulate S3 event
event = {
    'Records': [{
        's3': {
            'bucket': {'name': 'your-bucket'},
            'object': {'key': 'incidents/demo.log'}
        }
    }]
}
```

Give me your S3 bucket endpoint when ready! ğŸš€
